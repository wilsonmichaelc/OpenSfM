#!/usr/bin/env python

import argparse
import datetime
import logging
import os.path
import shutil
import yaml

from itertools import combinations
from timeit import default_timer as timer

from opensfm import bow
from opensfm import commands
from opensfm import dataset
from opensfm import features
from opensfm import io
from opensfm import log
from opensfm import matching


logger = logging.getLogger(__name__)
log.setup()


def create_bench_dir(dataset):
    dataset_dir = os.path.basename(os.path.normpath(dataset))

    base_dir = os.path.dirname(os.path.dirname(dataset)) if \
        os.path.isdir(dataset) else \
        os.path.dirname(dataset)

    bench_dir = os.path.join(
        base_dir,
        dataset_dir + \
        "_bench_feat_match_" + \
        datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S"))

    io.mkdir_p(bench_dir)

    return bench_dir


def create_brute_force_dataset(orig_dir, bench_dir):
    work_dir = os.path.join(bench_dir, "bruteforce")
    shutil.copytree(orig_dir, work_dir)

    config = load_config(work_dir)
    config["matcher_type"] = "BRUTEFORCE"
    save_config(config, work_dir)

    parser = argparse.ArgumentParser()
    parser.add_argument('dataset')
    args = parser.parse_args([work_dir])

    return dataset.DataSet(args.dataset)


def create_flann_dataset(orig_dir, bench_dir):
    work_dir = os.path.join(bench_dir, "flann")
    shutil.copytree(orig_dir, work_dir)

    config = load_config(work_dir)
    config["matcher_type"] = "FLANN"
    save_config(config, work_dir)

    parser = argparse.ArgumentParser()
    parser.add_argument('dataset')
    args = parser.parse_args([work_dir])

    data = dataset.DataSet(args.dataset)

    for image in data.images():
        p, f, c = data.load_features(image)
        index = features.build_flann_index(f, data.config)
        data.save_feature_index(image, index)

    return data


def create_words_dataset(orig_dir, bench_dir):
    work_dir = os.path.join(bench_dir, "words")
    shutil.copytree(orig_dir, work_dir)

    config = load_config(work_dir)
    config["matcher_type"] = "WORDS"
    save_config(config, work_dir)

    parser = argparse.ArgumentParser()
    parser.add_argument('dataset')
    args = parser.parse_args([work_dir])

    data = dataset.DataSet(args.dataset)

    for image in data.images():
        bows = bow.load_bows(data.config)
        n_closest = data.config['bow_words_to_match']
        p, f, c = data.load_features(image)
        closest_words = bows.map_to_words(
            f, n_closest, data.config['bow_matcher_type'])
        data.save_words(image, closest_words)

    return data


def load_config(work_dir):
    config = {}
    filepath = os.path.join(work_dir, "config.yaml")
    if os.path.isfile(filepath):
        with open(filepath) as fin:
            new_config = yaml.safe_load(fin)
        if new_config:
            for k, v in new_config.items():
                config[k] = v

    return config


def save_config(config, work_dir):
    with open(os.path.join(work_dir, 'config.yaml'), 'w') as fout:
        yaml.dump(config, fout, default_flow_style=False)


def match(data):
    images = data.images()
    images.sort()

    pairs = combinations(images, 2)
    comb = {im: [] for im in images}
    for im1, im2 in pairs:
        comb[im1].append(im2)

    matcher_type = data.config['matcher_type']

    for im1 in comb:
        im1_matches = {}

        print im1, comb[im1]

        for im2 in comb[im1]:
            # symmetric matching
            t = timer()
            p1, f1, c1 = data.load_features(im1)
            p2, f2, c2 = data.load_features(im2)

            if matcher_type == 'WORDS':
                w1 = data.load_words(im1)
                w2 = data.load_words(im2)
                matches = matching.match_words_symmetric(f1, w1, f2, w2,data.config)
            elif matcher_type == 'FLANN':
                i1 = data.load_feature_index(im1, f1)
                i2 = data.load_feature_index(im2, f2)
                matches = matching.match_flann_symmetric(f1, i1, f2, i2,data.config)
            elif matcher_type == 'BRUTEFORCE':
                matches = matching.match_brute_force_symmetric(f1, f2,data.config)
            else:
                raise ValueError("Invalid matcher_type: {}".format(matcher_type))

            im1_matches[im2] = matches

            logger.debug('{} - {} has {} initial matches'.format(
                im1, im2, len(matches)))

        data.save_matches(im1, im1_matches)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Benchmark feature matching algorithms')
    parser.add_argument('dataset',
                        help='path to the dataset to be processed')

    args = parser.parse_args()

    commands.extract_metadata.Command().run(args)
    commands.detect_features.Command().run(args)

    bench_dir = create_bench_dir(args.dataset)

    b_data = create_brute_force_dataset(args.dataset, bench_dir)
    f_data = create_flann_dataset(args.dataset, bench_dir)
    w_data = create_words_dataset(args.dataset, bench_dir)

    match(b_data)
    match(f_data)
    match(w_data)
